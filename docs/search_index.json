[["index.html", "STAT 451: Causal Inference Welcome!", " STAT 451: Causal Inference Welcome! Image source: Freepik This is the course website for STAT 451: Causal Inference at Macalester College for the Spring 2023 semester. The content here was made by Leslie Myint and draws upon several resources, all of which are listed on the References page. This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],["references.html", "References Required references References for review Further exploration", " References Required references [PRIMER]: Causal Inference in Statistics: A Primer, by Judea Pearl, Madelyn Glymour, and Nicholas P. Jewell. PDF freely available online. [WHATIF]: Causal Inference: What If, by Miguel A. Hern√°n and James M. Robins. PDF freely available online. References for review STAT 155 Notes: An online set of notes for STAT 155 written by the Macalester statistics faculty. Probability Essentials: A YouTube video outlining some key ideas from probability that we will use in this course. This article by Eleanor Murray has a great explanation of the most common misinterpretation of confidence intervals. Further exploration The Book of Why: The New Science of Cause and Effect, by Judea Pearl and Dana Mackenzie (Amazon) Causality: Models, Reasoning, and Inference, by Judea Pearl (available as an eBook through Macalester‚Äôs library) edX course: Causal Diagrams: Draw Your Assumptions Before Your Conclusions Udemy course: Causal Data Science with Directed Acyclic Graphs "],["schedule.html", "Schedule", " Schedule The schedule below is a tentative outline of our plans for the semester. If we need more time for digesting certain topics, we can make space for that. Before each class period, please watch the indicated videos, complete required readings, and work through the Guiding Questions. Responses to these questions don‚Äôt need to be turned in, but there will be many opportunities during class for you to check in with classmates about concepts you found confusing or intriguing. Remember to take notes on where you paused/rewound/reread or smiled/nodded during the videos/readings. This is essential for the Metacognitive Reflection part of the course. Most readings are optional‚Äìthey complement ideas in the videos by presenting concepts in a different way. (Note that the PRIMER and WHATIF abbreviations refer to free online textbooks listed on the References page.) When a reading is required, it will marked as (REQD). Week 1: Fun with Foundations (1/20 - 1/27) Dates Topic Videos/Readings Video Slides Class Slides 1/20 Motivation and Review &emsp;üëâ&ensp;Guiding ?s 1/23 Exchangeability &emsp;üëâ&ensp;Guiding ?s Defining Causal Effects Exchangeability WHATIF: 2.1, 2.2, 3.1, 3.2 1/25 Study Designs(and Exchangeability wrap-up) &emsp;üëâ&ensp;Guiding ?s Study Designs in Causal Inference WHATIF: 2.1, 2.2, 3.1, 3.2 N/A 1/27 Study Designs and Exchangeability wrap-up Homework 1 due Friday, 1/27 at midnight CST Week 2: Causal Graphs Galore! (1/30 - 2/3) Dates Topic Videos/Readings Video Slides Class Slides 1/30 Causal Graphs as Statistical Models &emsp;üëâ&ensp;Guiding ?s Introduction to Causal Graphs Causal Graphs as Statistical Models PRIMER: 1.4, 1.5 2/1 Key Structures in Causal Graphs &emsp;üëâ&ensp;Guiding ?s Key Structures in Causal Graphs PRIMER: 2.1 - 2.3 WHATIF: 6.1 - 6.3, 6.5 2/1 Key Structures in Causal Graphs (continued) Homework 2 due Friday, 2/3 at midnight CST Week 3: Gallivanting with Graphs (2/6 - 2/10) Dates Topic Videos/Readings Video Slides Class Slides 2/6 Graphical Structure of Confounding &emsp;üëâ&ensp;Guiding ?s Causal and Noncausal Paths D-Separation PRIMER: 2.4 WHATIF: 7.1 - 7.4, 7.6 2/8 Graphical Structure of Selection Bias &emsp;üëâ&ensp;Guiding ?s (REQD) WHATIF: 8.1 - 8.3 Optional: 8.4 - 8.6 2/10 The Smoking-Birthweight Paradox &emsp;üëâ&ensp;Guiding ?s (REQD) reading: The Birth Weight \"Paradox\" Uncovered? Start working on Homework 3 due Friday, 2/17 at midnight CST Week 4: Easing into Estimation (2/13 - 2/17) Dates Topic Videos/Readings Video Slides Class Slides 2/13 Catch-up day N/A 2/15 Building Causal Graphs for Applied Analyses &emsp;üëâ&ensp;Guiding ?s Asking Clear Questions and Building Graphs (REQD) reading: Equal but Inequitable: Who Benefits from Gender-Neutral Tenure Clock Stopping Policies? (Up through Section III: Data - about 6 pages total) N/A 2/17 Regression for Estimating Causal Effects &emsp;üëâ&ensp;Guiding ?s Estimating Causal Effects: Regression Finish working on Homework 3 due Friday, 2/17 at midnight CST Week 5: Wonders in Weighting (2/20 - 2/24) Dates Topic Videos/Readings Video Slides Class Slides 2/20 Regression Wrap-up & Inverse Probability Weighting for Estimating Causal Effects &emsp;üëâ&ensp;Guiding ?s Estimating Causal Effects: Inverse Probability Weighting WHATIF: 2.4 (parallels video) PRIMER: 3.6 (analogous viewpoint but different language than WHATIF) 2/22 Snow day - no class N/A 2/24 IPW (continued) Start working on Homework 4 due Friday, 3/3 at midnight CST (main exercises) and Friday 3/10 at midnight (project proposal) Week 6: Continuing with IPW (2/27 - 3/3) Dates Topic Videos/Readings Video Slides Class Slides 2/27 IPW: Simulation Study (REQD): WHATIF: 12.1, 12.2, 12.4 3/1 IPW: Applied Analysis 3/3 Capstone Days! (no class) Finish working on Homework 4 due Friday, 3/3 at midnight CST (main exercises) and Friday 3/10 at midnight (project proposal) Week 7: Learning Conferences (3/6 - 3/10) No class this week to make space for Learning Conferences. Schedule a conference with the instructor this week using the Google Calendar link under the Moodle course calendar (in the section titled \"Learning Conferences\"). The Google Calendar link shows time slots for the 9:40-10:40 and 10:50-11:50 sections of our course. If you'd like to have our conference outside of these times, use the Calendly link under the Moodle course calendar to schedule. Week 8: New Research Question Frameworks and Sensitivity Analyses (3/20 - 3/24) Dates Topic Videos/Readings Video Slides Class Slides 3/20 Overview: Time-Varying Treatments and Mediation 3/22 Sensitivity Analyses for Unmeasured Variables Sensitivity Analyses for Unmeasured Variables 3/24 Causal Discovery Causal Discovery Start Homework 5 due Wednesday, 3/29 at midnight CST Week 9: Revisiting Quasi-Experimental Designs (3/27 - 3/31) Dates Topic Videos/Readings Video Slides Class Slides 3/27 Regression Discontinuity (REQD video): Causality: Regression Discontinuity Design (REQD reading): Regression discontinuity designs are underutilized in medicine, epidemiology, and public health: a review of current and best practice (~11 pages) 3/29 Interrupted Time Series (REQD reading): The use of controls in interrupted time series studies of public health interventions (~10 pages) 3/31 Instrumental Variables (REQD video): Causality: Instrumental Variables (OPTIONAL reference: very long but comprehensive): Tutorial in Biostatistics: Instrumental Variable Methods for Causal Inference Finish Homework 5 due Wednesday, 3/29 at midnight CST Start Homework 6 due Friday, 4/7 at midnight CST Week 10: Project Work Dates Topic Videos/Readings Video Slides Class Slides 4/3 Project work day: mini-HW and intermediate project deliverables will be posted here 4/5 Project work day: mini-HW and intermediate project deliverables will be posted here 4/7 Project work day: mini-HW and intermediate project deliverables will be posted here Finish Homework 6 due Friday, 4/7 at midnight CST Week 11: Project Work Dates Topic Videos/Readings Video Slides Class Slides 4/10 Project work day: mini-HW and intermediate project deliverables will be posted here 4/12 Project work day: mini-HW and intermediate project deliverables will be posted here 4/14 Project work day: mini-HW and intermediate project deliverables will be posted here Week 12: Project Work Dates Topic Videos/Readings Video Slides Class Slides 4/17 Project work day: mini-HW and intermediate project deliverables will be posted here 4/19 Project work day: mini-HW and intermediate project deliverables will be posted here 4/21 Project work day: mini-HW and intermediate project deliverables will be posted here Week 13: Project Work Dates Topic Videos/Readings Video Slides Class Slides 4/24 Project work day: mini-HW and intermediate project deliverables will be posted here 4/26 Project work day: mini-HW and intermediate project deliverables will be posted here 4/28 Project work day: mini-HW and intermediate project deliverables will be posted here Work on Final Project due Saturday, 5/6 at midnight CST Week 14: Project Work Dates Topic Videos/Readings Video Slides Class Slides 5/1 Project work day: mini-HW and intermediate project deliverables will be posted here Work on Final Project due Saturday, 5/6 at midnight CST "],["guiding-questions.html", "Guiding Questions", " Guiding Questions Motivation and Review Let‚Äôs think about the word ‚Äúcause‚Äù (and related phrases like ‚Äúresults in‚Äù and ‚Äúleads to.‚Äù) What do you think ‚Äúcause‚Äù means? How do you/people you know use it in day-to-day conversation and thinking? Why do we want to learn about causes? What should our goals be in learning about causes? ‚ÄúCorrelation does not imply causation.‚Äù Has this saying come up in conversations occasionally? If so, how? How do you feel about the value of this saying? Exchangeability Is the definition of a potential outcome and a causal effect satisfying to you? How do these notions relate to what you had thought about causes and causation previously? (Reflect on and connect to our Day 1 activity.) Let‚Äôs think about exchangeability in big picture terms. Setting aside the technical definitions in terms of (conditional) independence, what is exchangeability trying to describe? Try to find a good word/phrase (not ‚Äúindependent‚Äù) to complete the following sentence: ‚ÄúIf the treated and untreated groups are exchangeable, we could also describe them as being ‚Ä¶‚Äù How can we use the concepts of marginal and conditional exchangeability to make statements about potential outcome distributions in the treated and in the untreated? Marginal and conditional exchangeability are assumptions‚Äìdo you think these assumptions are testable using data? Why or why not? Extra self-check resource: Moodle checkpoint on Causal Effects and Exchangeability Study Designs Why are randomized experiments often called the ‚Äúgold standard‚Äù for causal inference? What is the relationship between randomized experiments and exchangeability? Consider the quasi-experimental designs discussed in the video. How do these designs try to mimic randomization? What assumptions do they make to allow making statements about missing potential outcomes? Extra self-check resource: Moodle checkpoint on Study Designs for Causal Inference Causal Graphs as Statistical Models Why is it sensible for causal graphs to be directed and acyclic? How can ‚Äúfeedback loops‚Äù be represented in causal graphs? What extra information does a structural equation model encode that a causal graph alone does not? Extra self-check resource: Moodle checkpoint on Causal Graphs as Statistical Models Key Structures in Causal Graphs What marginal and conditional (in)dependence relations pertain to chains, forks, and colliders? Do these relations make sense? What examples (in the video or your own) help rationalize these relations? Extra self-check resource: Moodle checkpoint on Key Structures in Causal Graphs Graphical Structure of Confounding What is the relationship between d-separation, causal/noncausal paths, conditional exchangeability, and estimating causal effects? Extra self-check resource: Moodle checkpoint on (Non)causal Paths and D-Separation Graphical Structure of Selection Bias How is selection bias different from confounding bias? The Smoking-Birthweight Paradox What is the paradox/surprising finding at the center of this paper? What data are presented that illustrate this surprising finding? How do the authors use causal graphs to explain the paradox? Do you find the discussion of causal graphs helpful? Why or why not? Building Causal Graphs for Applied Analyses The video describes a way to think through building a causal graph for an applied analysis. Do you agree with the rationale for the thought process? Are there any other aspects of the graph-building process that you have questions about? (e.g., How would a given step work out in practice?) Regression for Estimating Causal Effects What is the connection between conditional exchangeability and the variables needed to include in a regression model for estimating causal effects? What steps can we take to ensure that the form of our regression model is as accurate as possible? What concerns arise when trying to interpret all coefficients (not just the treatment coefficient) from regression output? "],["motivation-and-review.html", "Topic 1 Motivation and Review Discussion prompts", " Topic 1 Motivation and Review Slides from today are available here. Discussion prompts Reminder: Make note of both your gut reactions and those of your peers. Today is all about noticing the subtle and unconcious ways that we think about causation, so these gut reactions are treasures worth capturing! As you discuss, add these noticings and your thoughts to the prompts to this Google Doc so that we have a shared class resource. Considering causes Given that we‚Äôre in a class called Causal Inference, it‚Äôs worth thinking deeply about the notions of causes and causation. Consider the word ‚Äúcause‚Äù (and related phrases like ‚Äúresults in‚Äù and ‚Äúleads to.‚Äù) What do you think ‚Äúcause‚Äù means? How do you/people you know use it in day-to-day conversation and thinking? Why do we want to learn about causes? What should our goals be in learning about causes? Sinful saying or mandatory mantra? Correlation does not imply causation. How has this saying come up in conversation for you? How do you feel about the value of this saying? Consider the following scenarios. What are your reactions to using this saying in each of them? Days with higher ice cream sales tend to have higher crime rates. Individuals with larger shoe sizes tend to have better reading ability. Individuals who practice meditation tend to experience less stress. Individuals who regularly smoke cigarettes tend to develop lung cancer at higher rates than nonsmokers. Sufficiency and necessity Consider the following statements: If X happens, then Y will happen. If X does not happen, then Y will not happen. Are these statements redundant? (Do they give identical information about X and Y?) Why or why not? Evaluating evidence for causation: Bradford Hill criteria In 1965, epidemiologist Sir Austin Bradford Hill propsed a set of nine criteria for evaluating evidence for a causal relationship. Let‚Äôs explore these criteria and reflect on how it fits into our mental frameworks on causation. Lucy D‚ÄôAgostino McGowan has a fun presentation that explains Hill‚Äôs criteria through XKCD comics. What criteria do you find most/least compelling? "],["exchangeability.html", "Topic 2 Exchangeability Learning Goals Exercises Exercise 7 (Extra)", " Topic 2 Exchangeability Learning Goals Define an average causal effect in terms of potential outcomes Apply the concepts of marginal and conditional exchangeability to answer questions about (hypothetical) data on potential outcomes Give examples of when marginal and conditional exchangeability would and would not hold in various data contexts Explain why a direct comparison of the outcomes in the treated and untreated is misleading as an estimate of a causal effect Slides from today are available here. Exercises Exercise 1 Suppose that we are trying to understand the causal effect of a personal finance course on the percent of earnings left in savings each month (abbreviated as ‚Äúpercent savings‚Äù). For the 500 people who took the course, we are able to collect data on percent savings and various other factors. We are also able to collect the same information from 500 people who did not take the course. Do you think that a comparison of percent savings in the course takers and non-takers would be a valid estimate of the average causal effect? Explain your viewpoint using the concepts of potential outcomes and exchangeability. One important factor to consider is the number of children that an individual has. Explain how this factor could contribute to a lack of exchangeability in the outcomes of the course takers and non-takers. As part of your explanation, discuss how observed outcomes compare to the missing potential outcomes. State any assumptions you make about the relationships between different factors. Do you think conditional exchangeability holds conditional on number of children? If yes, why? If no, what other factors might be needed to achieve conditional exchangeability? What is your thought process in thinking about other factors? Exercise 2 While \\(Y^a\\) denotes the potential outcome under treatment \\(A = a\\), \\(Y\\) denotes the observed outcome. (For the treated, \\(Y = Y^{a=1}\\). For the untreated, \\(Y = Y^{a=0}\\).) Is it possible for marginal exchangeability to hold but for \\(Y\\) and \\(A\\) to be dependent? Explain using a numerical or graphical example. Exercise 3 We have the data below on number of children (\\(Z\\)), treatment (course takers: \\(A = 1\\). course non-takers: \\(A = 0\\)), and the percent savings outcome (\\(Y^a\\)) categorized as either high (H) or low (L). Assuming that the course takers and non-takers are exchangeable conditional on number of children, estimate the average causal effect \\(P(Y^{a=1} = \\mathrm{high}) - P(Y^{a=0} = \\mathrm{high})\\). \\(n\\) \\(Z\\) \\(A\\) \\(Y\\) 10 2 1 7 H, 3 L 10 1 1 6 H, 4 L 10 0 1 5 H, 5 L 30 2 0 18 H, 12 L 40 1 0 20 H, 20 L 50 0 0 20 H, 30 L Exercise 4 Assuming that we have exchangeability of the course takers and non-takers conditional on number of children (\\(Z\\)) and use of public transportation (\\(W\\)), how might a regression model be used to estimate the average causal effect of the personal finance course? Exercise 5 Exchangeability is a core assumption in causal inference. Do you think it is possible to test this assumption with data? If yes, how? If not, why not? Exercise 6 (Extra) Consider the 4 scenarios below. For all scenarios, \\(A\\) represents a binary treatment, and \\(Y\\) represents the observed outcome (quantitative). Marginal exchangeability, independence of \\(Y\\) and \\(A\\) Marginal exchangeability, dependence of \\(Y\\) and \\(A\\) Lack of marginal exchangeability, independence of \\(Y\\) and \\(A\\) Lack of marginal exchangeability, dependence of \\(Y\\) and \\(A\\) Draw plots of potential outcome distributions or create numerical examples that illustrate the following 4 scenarios. Exercise 7 (Extra) Does marginal exchangeability imply conditional exchangeability? Does conditional exchangeability imply marginal exchangeability? If yes, why? If not, provide a numerical example showing a counterexample. "],["study-designs.html", "Topic 3 Study Designs Learning goals Exercises", " Topic 3 Study Designs Learning goals Identify appropriate study designs for answering causal questions based on a description of available data Explain how study designs ‚Äúwork‚Äù to estimate causal effects. Explain what assumptions they make to make statements about missing potential outcomes. Slides from today are available here. Exercises Peer check-in Start by checking on the guiding questions: Why are randomized experiments often called the ‚Äúgold standard‚Äù for causal inference? What is the relationship between randomized experiments and exchangeability? Consider the quasi-experimental designs discussed in the video. How do these designs try to mimic randomization? What assumptions do they make to allow making statements about missing potential outcomes? What ideas were confusing, less clear, or intriguing? Make note of what your peers have noticed. This is a gold mine of information for your Metacognitive Reflections. Exercise 1 When dealing with an infection, should we suppress fever (e.g., with Tylenol or Motrin) or let the fever run its course? Randomized experiments have been used to examine this question. (Source 1, Source 2) Why might we want to use stratified randomization to examine the effect of fever suppressors on health outcomes? What variables might we want to stratify on and why? ‚ÄúBlinding‚Äù refers to the act of hiding from researchers and study participants the treatment group that the patients are actually in. Blinding is an important design consideration in randomized experiments. Suppose that hospital caregivers are not blinded and know whether a patient is receiving fever suppressors or not. How might this lead to a lack of exchangeability? What if patients knowing their treatment group? How might this lead to a lack of exchangeability? Compliance with assigned treatment is a practical concern in randomized experiments. What could be a reason for a patient‚Äôs lack of compliance with assigned treatment, and how might this affect exchangeability? Randomized trials with noncompliance can be viewed as an instrumental variables design. Explain this connection. (What is the instrument, and what is the treatment of interest?) Exercise 2 Radon is an element naturally found in air that can cause lung cancer. It has a very low concentration outdoors and can have higher concentrations indoors. When buying a home, a radon check is typically ordered to assess if the home needs a radon mitigation system installed (a system to reduce radon levels). If radon levels are above a certain threshold, a radon mitigation system is recommended. Given this context, what study design(s) might be used to study the effect of radon mitigation systems on lung cancer rates? Exercise 3 Interrupted time series analyses typically use models that can handle the correlated nature of time series data. (If you are curious about these methods, take STAT 452: Correlated Data!) For now, we can gain intuition for how these models are used in practice by examining linear regression models. The general form of a linear regression model for an interrupted time series design is below: \\[ E[Y \\mid T, I, A] = \\beta_0 + \\beta_1 T + \\beta_2 I + \\beta_3 TI + \\beta_4 A + \\beta_5 AT + \\beta_6 AI + \\beta_7 AIT \\] \\(Y\\): outcome/response variable \\(T\\): time \\(I\\): 1 if in the time period post-intervention, 0 for pre-intervention \\(A\\): 1 for treatment sites receiving the intervention, 0 for control sites Draw a figure showing the relationship between \\(Y\\) and \\(T\\) and showing how the slopes change over time and in between treatment vs.¬†control sites. Label slopes, intercepts, and any changes or discontinuities with model coefficients. Ideally, control units should have pre-intervention trends that are as similar as possible to the pre-intervention trends for units that are treated. If this is the case, for which coefficients should we expect the confidence intervals to overlap zero? Which coefficients represent the causal effect of the intervention, and how can we interpret them? Extra If you have time, work on Part 4 of Homework 1, and get feedback from peers about your proposed study. "],["causal-graphs-as-statistical-models.html", "Topic 4 Causal Graphs as Statistical Models Learning Goals Simulating data in R Exercises", " Topic 4 Causal Graphs as Statistical Models Learning Goals Apply the Causal Markov assumption to express the joint distribution of data. Simulate data from causal graphs under linear and logistic regression structural equation models. Formulate use cases of simulation to understand causal inference concepts Slides from today are available here. Simulating data in R You can download a template RMarkdown file to start from here. Why simulate? Simulation is a very powerful tool for understanding statistical ideas. We can simulate (generate) data where we know the true underlying distribution, and we can then see how statistical methods perform on this data. For example: Do 95% confidence intervals really contain the true population value in 95% of samples? When is this not true? Does regression work to estimate causal effects when we have conditional exchangeability? Simulation functions in R R has functions to work with several probability distributions. For example, the following 4 functions work with the normal distribution: rnorm(): Generate a random number from a normal distribution pnorm(): Tail probability from a normal distribution dnorm(): Get density value from a normal distribution qnorm(): Get a quantile from a normal distribution There are r, p, d, and q functions for other distributions too (e.g., runif(), rbinom().) We‚Äôll primarily use r functions to generate random numbers. rbinom(): # 4 different people each flip a fair coin once rbinom(4, size = 1, prob = 0.5) # 4 different people flip unfair coins # First 2 flip a coin with P(Heads) = 0.9 # Second 2 flip a coin with P(Heads) = 0.2 rbinom(4, size = 1, prob = c(0.9, 0.9, 0.2, 0.2)) # Write a command with rbinom() so that the result will definitively be 1,0,1 rnorm(): # 5 numbers from a normal distribution with mean 10 and SD 2 rnorm(5, mean = 10, sd = 2) # 3 numbers from 3 different normal distributions # Means = 10, 100, 1000. SD = 1 rnorm(3, mean = c(10, 100, 1000), sd = 1) # Write a command with rnorm() so that the result will definitively be 10,20 Simulating data from graphs+SEMs In this course, we‚Äôll simulate data that come from graphs and their corresponding structural equation models. We‚Äôll step through how to simulate data that come from this causal graph. Question: Using the Causal Markov Assumption, how can we express the joint distribution of this data? Consider the structural equation model (SEM) below that is associated with our causal graph: \\[ \\begin{align*} Z &amp;\\sim N(\\mu_Z = 40, \\sigma_Z = 5) \\\\ A &amp;\\sim \\mathrm{Binomial}(n = 1, p_A) \\\\ \\qquad &amp;\\log\\left(\\frac{p_A}{1-p_A}\\right) = -1 + 0.05Z \\\\ Y &amp;\\sim N(\\mu_Y, \\sigma_Y = 1) \\\\ \\mu_Y &amp;= 30 + 5A + 2Z \\end{align*} \\] \\(Z\\) is an exogenous variable that follows a normal distribution with mean 40 and standard deviation 5. \\(A\\) is binary (binomial/Bernoulli) with probability of success \\(p_A\\) \\(p_A\\) depends on \\(Z\\) via a logistic regression model. \\(Y\\) is quantitative and follows a normal distribution. The mean \\(\\mu_Y\\) depends on \\(A\\) and \\(Z\\) via a linear regression model. Complete the code below to simulate data that follow this structural equation model. set.seed(451) # For reproducibility # Sample size n &lt;- 10000 # Simulate the Z variable Z &lt;- rnorm(?) # Simulate the A variable log_odds_A &lt;- -1 + 0.05*Z odds_A &lt;- exp(log_odds_A) p_A &lt;- odds_A/(1+odds_A) A &lt;- rbinom(?) # Simulate the Y variable mean_Y &lt;- 30 + ? noise_Y &lt;- rnorm(n, mean = 0, sd = 1) Y &lt;- mean_Y + noise_Y # Store all simulated variables in a dataset called sim_data sim_data &lt;- data.frame(Z, A, Y) After generating simulated data, it‚Äôs best to use plots and summary measures to make sure that marginal distributions and relationships between variables look sensible. # Explorations to check sensibility of simulated data Exercises You‚Äôll need to install the dagitty package before getting started. Exercise 1 Write the joint distribution of the data from the causal graph below using the Causal Markov Assumption. Simulate data from the graph. You are free to choose your own structural equation model, but let \\(Z\\), \\(W\\), and \\(Y\\) be quantitative. Let \\(A\\) be binary. Use a sample size of 10,000 for your simulation. Use plots and summary measures to ensure that the simulated data have reasonable properties. Based on the structural equation model you chose, what would you guess is the average causal effect \\(E[Y^{a=1} - Y^{a=0}]\\)? Let‚Äôs consider simulating interventions using your SEM. If you were to force all study units to receive a certain value of treatment (either 0 or 1), how do you think the causal graph would change? Modify your simulation to reflect your thoughts from part d.¬†Incorporate the code below into your simulation. # Scenario 1: Force all to be treated A_force_1 &lt;- rep(1, n) # Repeat the number 1 n times # Scenario 2: Force all to be treated A_force_0 &lt;- rep(0, n) # Repeat the number 0 n times # The treated potential outcome Y^{a=1} Y1 &lt;- ? # something with A_force_1 # The untreated potential outcome Y^{a=0} Y0 &lt;- ? # something with A_force_0 # Estimate the average causal effect mean(?) Was your intuition from part b close to the ACE that you estimated in the simulation? Extra Try organizing the simulation code from today into general-purpose functions that can be used in subsequent simulations. "],["key-structures-in-causal-graphs.html", "Topic 5 Key Structures in Causal Graphs Learning Goals Exercises", " Topic 5 Key Structures in Causal Graphs Learning Goals Explain the intuition behind marginal and conditional (in)dependence relations in chains, forks, and colliders in causal graphs Simulate data from causal graphs under linear and logistic regression structural equation models to check these properties through regression modeling and visualization Slides from today are available here. Exercises You can download a template RMarkdown file to start from here. In these exercises, you‚Äôll be practicing simulating data from structural equation models and verifying marginal and conditional (in)dependence properties in DAG structures. Always use a regression model as a check. If the situation readily corresponds to a plot, also make a plot as a check. Coding note: When you simulate binary variables and store them in a dataset, it is useful to store them explicitly as categorical as below. (This is most helpful for plotting.) # X is binary. Y and Z are quantitative. sim_data &lt;- data.frame(X = factor(X), Y, Z) Exercise 1 Simulate a chain X -&gt; Y -&gt; Z where all three variables are quantitative. (Use a sample size of 10,000 and a significance level of 0.05 throughout these exercises.) What conditional relationship is implied by this chain structure? What is the intuition behind/rationale for this relationship? Use appropriate check(s) to verify this conditional relationship. Exercise 2 Simulate a fork X &lt;- Y -&gt; Z where X and Z are quantitative, and Y is binary. What conditional relationship is implied by this fork structure? What is the intuition behind/rationale for this relationship? Use appropriate check(s) to verify this conditional relationship. Exercise 3 Simulate a collider X -&gt; Y &lt;- Z where Y also has a child A (Y -&gt; A). Let all 4 variables be binary. What marginal and conditional relationships between X and Z are implied by this collider structure? What is the intuition behind/rationale for this relationship? Use appropriate check(s) to verify these relationships. Exercise 4 Can we extend building block thinking to longer, more complex structures? Let‚Äôs investigate here (conceptually, no simulation). Consider the longer structure A &lt;- B &lt;- C -&gt; D. What do you expect about marginal/conditional (in)dependence of A and D? Explain. Consider the longer structure A -&gt; B &lt;- C &lt;- D -&gt; E. What do you expect about marginal/conditional (in)dependence of A and E? Explain. Extra If you would like to delve more into the probability theory behind these ideas, try the following exercise. Use the Causal Markov assumption/product decomposition rule to prove: The conditional independence relations in forks and chains The marginal independence and conditional dependence relations in colliders "],["graphical-structure-of-confounding.html", "Topic 6 Graphical Structure of Confounding Learning Goals Exercises", " Topic 6 Graphical Structure of Confounding Learning Goals Explain how d-separation and causal/noncausal paths relate to exchangeability and causal effects. Apply d-separation to block noncausal paths in causal DAGs with and without unobserved variables. Apply strategies to deal with exchangeability problems caused by unobserved variables. Slides from today are available here. Exercises Exercise 1 For each of the causal graphs below, identify the set of variables needed to achieve conditional exchangeability of the treatment groups \\(A\\) for outcome \\(Y\\) (if possible). Any \\(U\\) variables displayed in the graphs are unobserved/unmeasured. Show your work. Exercise 2 When constructing causal graphs from expert knowledge, there are generally important variables that are unmeasurable (e.g., behaviors, living situations). In this exercise, we‚Äôll consider how we might deal with these unmeasured factors in practice. Suppose that in the graphs below, the variables represent the following: \\(A\\): Regular participation in high-intensity interval training (HIIT) (the treatment of interest) \\(Y\\): Cardiovascular disease \\(U\\): Personality traits In this context, describe what \\(L\\) might be in each graph (\\(L\\) could represent multiple variables). What do these graphs illustrate about a general strategy for dealing with exchangeability problems caused by unmeasured variables? Exercise 3 Historically, people have tried to create definitions for confounders by listing criteria that purely rely on associations. For example: A confounder must: 1. Be associated with treatment and outcome 2. Not be caused by treatment Using the causal graph below, explain why this is not a good definition for a confounder. "],["graphical-structure-of-selection-bias.html", "Topic 7 Graphical Structure of Selection Bias Learning Goals Exercises", " Topic 7 Graphical Structure of Selection Bias Learning Goals Apply d-separation to block noncausal paths in causal DAGs with and without unobserved variables Differentiate confounding and selection bias in terms of graph structure and how they arise in applied studies Slides from today are available here. Exercises Navigate to DAGitty and click the ‚ÄúLaunch online‚Äù link. Exercise 1 First, think through the relationships depicted in the causal graphs below and whether they make sense. These are intended to reflect a range of scenarios for why people drop out of studies. Then for each of the graphs, identify the set of variables needed to achieve conditional exchangeability of the treatment \\(A\\) and outcome \\(Y\\). (\\(U\\) and \\(W\\) are unmeasured.) Check your answers to one of the graphs using DAGitty. Exercise 2 In this exercise, we‚Äôll consider how causal graphs can inform study design. (Inspired by a 1970s study on the relationship between estrogen use and endometrial cancer.) Researchers have noticed a consistent association between use of a certain drug and disease. Research groups debated two hypotheses: The drug does cause disease. The drug doesn‚Äôt actually cause disease but leads to a side effect, leading to more frequent doctor visits, leading to increased diagnosis of existing disease. The following study plan was proposed: restrict the study only to those with side effects and compare disease rates in drug-users and non-users. In this way, all participants have the same chance of being diagnosed. The following causal graphs correspond to the two hypotheses: (The graphs don‚Äôt show confounders of the drug-true disease relationship for compactness. We can assume that these have already been adjusted for.) Study design 1 Consider the study proposal above: restrict analysis to those with side effects. Before looking at the causal graphs: does the rationale for this study design make sense? Why did researchers want to only look at patients with side effects? Under this study design, the researchers were expecting that if Hypothesis 1 were correct (the drug does cause disease), they would find an association between drug use and diagnosed disease. They expected that if Hypothesis 2 were correct (the drug does NOT cause disease), they would find NO association between drug use and diagnosed disease. Are these expectations correct? Explain in light of the causal graphs. Based on your answer above, is this an effective study design for the research questions of interest? That is, can this study proposal distinguish between the two hypotheses? Study design 2 Consider another study proposal: ensure that everyone is screened for disease frequently, and we don‚Äôt restrict our analysis to only those with side effects. What arrow can be removed as a result of this study design? (It might help to draw an updated version of DAGs 1 and 2 with this arrow removed.) Under this study design, the researchers had the same expectations: if Hypothesis 1 were correct, they would find an association between drug use and diagnosed disease. If Hypothesis 2 were correct, they would find NO association between drug use and diagnosed disease. Are these expectations correct? Explain in light of the causal graphs. Based on your answer above, is this an effective study design for the research questions of interest? That is, can this study proposal distinguish between the two hypotheses? Exercise 3 In 2020, a COVID-19 risk factory study received a lot of press for the surprising finding that smoking seemed protective for COVID-19 mortality. Dr.¬†Eleanor Murray posted a series of Tweets diving into the situation from a causal graphs perspective. Read through her Tweets and discuss the following: How might we explain the paradoxical protective effect of smoking found in the risk factor study? Dr.¬†Murray also discusses the importance of clarifying a causal question and the ‚ÄúTable 2 Fallacy.‚Äù Did any of these other ideas resonate with you, pique your curiosity, or leave you uncertain? Comment on the structure of the Tweetorial. What was effective and less effective? Would you have presented the information differently? Using different causal graphs? (If you feel inclined, put your ideas in Tweet form!) "],["the-smoking-birth-weight-paradox.html", "Topic 8 The Smoking-Birth Weight Paradox Our Task", " Topic 8 The Smoking-Birth Weight Paradox Slides from today are available here. Our Task Goal: Create a set of slides for a capstone-style presentation explaining the paradox in story form. Aim for the presentation to be fully accessible to STAT 451 students who have not read the paper, and to be somewhat accessible to STAT 155 students. Group roles: To facilitate our work today, it may be helpful to divide the work along the following group roles: Recorder: This person is crafting the slides (with guidance from others). This person creates the Google Slides file and shares it with the team and the instructor. Referencer: This person has the paper open to refer to key claims. Visioner: This person keeps the big picture in mind to guide the construction of the presentation. Facilitator: This person keeps everyone on track, manages time, and ensures that works is progressing at a good pace. Checker: This person monitors the accuracy of what has been created and keeps the guiding prompts below in mind, bringing them into the discussion when appropriate. Guiding prompts: Use these prompts to guide the crafting of your presentation to ensure that you consider key points: In all causal diagrams considered in this paper, no confounders of maternal smoking and mortality are shown. Given the intent of the paper, do you think this is a problem? Consider the choice and sequencing of causal diagrams presented in the paper. Which of Figures 3.1-3.6 will you choose to highlight in your presentation? (Figure 3.7 is the most complete and should go in your presentation.) It may help to use Figure 3.6 to outline your explanation before tackling the more complex Figure 3.7. Both collider stratification and relative effect magnitudes (strengths of relationships along individual arrows) will be important in your explanation. The discussions in the paper focus on the impacts of conditioning on Low birth weight = Yes. Do you think the paradox would hold if we condition on Low birth weight = No? (If time permits) Incorporate the alcoholism-liver cancer example at the end of the paper (just before the Discussion section). "],["building-causal-graphs-for-applied-analyses.html", "Topic 9 Building Causal Graphs for Applied Analyses Learning Goals Exercises", " Topic 9 Building Causal Graphs for Applied Analyses Learning Goals Practice building causal graphs to answer causal questions in an applied setting Exercises Data context In 2019, The New York Times featured research by a group who studied the effect of tenure-clock stopping policies on tenure outcomes. We‚Äôll be looking at data from the study Equal but Inequitable: Who Benefits from Gender-Neutral Tenure Clock Stopping Policies? by Antecol, Bedard, and Stearns. The cases in the data represent individual faculty members in economics departments at top-50 schools. For each faculty member, we have information on several different tenure outcomes, career information, and school characteristics. Research questions: What is the effect of working at an institution with a gender-neutral tenure clock stopping policy on tenure outcomes? How is this effect different for men and women? (The authors only collected information on binary gender.) Collaborative causal graph construction Using the thought process described in our pre-class concept video, construct a causal graph that captures crucial information for our context. This will be hard. It will involve substantial discussion and uncertainty. All of this is part of the process. The instructor will serve as a subject-matter expert. Consult with her on any questions that arise. If you want to get up and move around, feel free to draw your DAG on the whiteboards. Others not at the whiteboard should record thoughts on DAGitty. Start by adding the treatment and outcome and identifying common causes of the treatment and outcome. To identify common causes, it can be helpful to start by just brainstorming causes of the outcome. Then determine if/how these causes might be related to treatment. Think through the common causes of pairs of variables that are not the treatment-outcome pair. This is likely harder than the previous step. And you may be worried about an infinite regress of common causes (when can we stop?!). If you are struggling to identify these common causes, it‚Äôs quite possible that they are of such small importance so as to not matter. You can check to see if including a common cause would actually change the conditional exchangeability set. As you go through this process, make note of what you are uncertain about and what aspects are hard. Not only is this useful metacognitive information, but it‚Äôs also likely that you are experiencing troubles that could be helped with further methodological and/or software development. Incorporate information on available variables Below is an abbreviated description of the variables available in our data. Goals for this phase: See which variables on your graph correspond directly to available variables. Replace the name of the variable on your graph with the variable name from the list below. Based on your graph, what variables are needed to achieve conditional exchangeability? If any of these variables did not have a direct mapping from Step 1, these may potentially be unobserved factors (threatening conditional exchangeability). Are there any variables below that would be good proxies/surrogates for those factors? If at the end of this process, you still have unobserved variables in your conditional exchangeability set, that‚Äôs fine. Just note what those are. (Later in the semester we‚Äôll learn about tools for addressing the potential impact of unmeasured variables.) Treatment and primary outcome: gncs: Is a gender-neutral clock-stopping policy in place at this person‚Äôs school? (treatment) tenure_policy_school: Did this person get tenure at the university with the clock-stopping policy? (primary outcome) Additional outcomes (mediators): top_pubsX: cumulative number of peer-reviewed publications in top-5 journals by year X (3, 5, 7, and 9) since PhD completion PUBSX: cumulative number of non-top-5 peer-reviewed publications by year X (3, 5 7, and 9) since PhD completion Additional covariates: female: Is the faculty member a female? pol_u: policy university identifier (values are randomized for privacy reasons) pol_job_start: identifier for year the job at the policy university started (values are randomized for privacy reasons) phd_rank: 1-5 categorical variable of PhD program tier based on placements into the top-50 departments in our sample phd_rank_miss: indicator for missing PhD information post_doc: indicator for doing a post-doc before the first tenure-track position ug_students: number of undergraduate students at the university, in thousands grad_students: number of graduate students at the university, in thousands faculty: number of faculty at the university (all disciplines), in hundreds full_av_salary: average salary of full professors at the university, in thousands assist_av_salary: average salary of assistant professors at the university, in thousands, revenue: annual revenue of the university, in 10,000,000s female_ratio: fraction of the faculty at the university who are female full_ratio: fraction of the faculty at the university who are full professors any_birth: indicator for having at least one child within 5 years of PhD completion all_birth: number of children by 5 years after PhD completion havekids: indicator for ever having at least one child numkids: number of children ever born (Information on additional variables is available in the ReadMe file in this folder on Moodle.) "],["applied-analysis-regression.html", "Topic 10 Applied Analysis: Regression Learning Goals Analysis Simulation study planning", " Topic 10 Applied Analysis: Regression Learning Goals Conduct and interpret results from a regression analysis to estimate average causal effects and subgroup average causal effects Slides from today are available here. Analysis You can download a template RMarkdown file to start from here. Data context and research questions library(tidyverse) library(splines) # Make sure that the splines package is installed before running tenure &lt;- read_csv(&quot;aer_primarysample.csv&quot;) tenure &lt;- tenure %&gt;% mutate( faculty = ifelse(faculty_miss==1, NA, faculty), revenue = ifelse(revenue_miss==1, NA, revenue), female_ratio = ifelse(female_ratio_miss==1, NA, female_ratio), full_ratio = ifelse(full_ratio_miss==1, NA, full_ratio), phd_rank = ifelse(phd_rank_miss==1, NA, phd_rank), max_csstops = ifelse(max_csstops_miss==1, NA, max_csstops) ) Research questions: Does a policy that delays the tenure process (for new parents) actually help tenure outcomes? Does it help men and women equally? The data and full codebook are available on Moodle (aer_primarysample.csv and ReadMe.pdf). An abbreviated codebook is below: Treatment and primary outcome: gncs: Is a gender-neutral clock-stopping policy in place at this person‚Äôs school? (treatment) tenure_policy_school: Did this person get tenure at the university with the clock-stopping policy? (primary outcome) Additional outcomes (mediators): top_pubsX: cumulative number of peer-reviewed publications in top-5 journals by year X (3, 5, 7, and 9) since PhD completion PUBSX: cumulative number of non-top-5 peer-reviewed publications by year X (3, 5 7, and 9) since PhD completion Additional covariates: female: Is the faculty member a female? pol_u: policy university identifier (values are randomized for privacy reasons) pol_job_start: identifier for year the job at the policy university started (values are randomized for privacy reasons) phd_rank: 1-5 categorical variable of PhD program tier based on placements into the top-50 departments in our sample phd_rank_miss: indicator for missing PhD information post_doc: indicator for doing a post-doc before the first tenure-track position ug_students: number of undergraduate students at the university, in thousands grad_students: number of graduate students at the university, in thousands faculty: number of faculty at the university (all disciplines), in hundreds full_av_salary: average salary of full professors at the university, in thousands assist_av_salary: average salary of assistant professors at the university, in thousands, revenue: annual revenue of the university, in 10,000,000s female_ratio: fraction of the faculty at the university who are female full_ratio: fraction of the faculty at the university who are full professors RANK: equal to 1 for top-10 departments and 2 for all other departments max_csstops: number of children born within five years of PhD completion Part 1: Finalize adjustment set If you constructed your causal graph on DAGitty last class, paste your model code into this Google Doc, and report the variables needed to achieve conditional exchangeability. Pick one graph to focus on for the remainder of this analysis. Open DAGitty and paste the model code from the Google Doc into the ‚ÄúModel code‚Äù pane on the right. Click ‚ÄúUpdate DAG‚Äù to view the graph. Spend a short amount of time reviewing this graph to see if you generally agree with the relationships depicted. Make any updates that you think are sensible. (Again, keep this short - in practice, this should take weeks of thorough literature review and expert consultation.) If any variables do not directly correspond to available variables, find proxies for them. (Several variables may end up serving as a proxy for one unmeasured variable on your graph.) Based on this, decide on your final adjustment set. Part 2: Exploratory analysis Construct visualizations to inform your regression model specification. Your visualizations should: Explore nonlinear relationships between conditioning variables and the outcome Explore an interaction between one pair of conditioning variables. (To keep our analysis short) Note: All of the variables are coded as numeric, so if you need to make bar plots, you may need to wrap the variable name inside factor(), e.g., factor(female). The code below will be useful for exploring nonlinearity in covariate-outcome relationships. The blue smooth reflects observed data trends, and the red smooth shows the predictions from a logistic regression model with a specific model formula. Formula y ~ x: Covariate is included as a linear term Formula y ~ ns(x,3): Covariate is modeled with a flexible nonlinear function (a ‚Äúspline‚Äù with 3 degrees of freedom‚Äìdon‚Äôt worry about the details of this) The model predictions should generally align with observed data trends. If they don‚Äôt line up well using formula y ~ x, update the formula to y ~ ns(x, 3) to see if there is an improvement. ggplot(data, aes(x = covariate, y = tenure_policy_school)) + geom_point() + geom_smooth(se = FALSE, color = &quot;blue&quot;, method = &quot;loess&quot;) + geom_smooth(formula = INSERT_MODEL_FORMULA, method = &quot;glm&quot;, method.args = list(family=&quot;binomial&quot;), se = FALSE, color = &quot;red&quot; ) Part 3: Modeling Fit a model to estimate the overall average causal effect and another to estimate the subgroup average causal effects for males and females. (Recall: A*B in a model formula creates an interaction between A and B.) For both models, display the summarized output table and 95% confidence intervals for the coefficients of interest. Interpret the coefficients of interest on the natural (exponentiated) scale. mod_overall &lt;- glm(INSERT_MODEL_FORMULA, data = tenure, family = &quot;binomial&quot;) mod_bygender &lt;- glm(INSERT_MODEL_FORMULA, data = tenure, family = &quot;binomial&quot;) summary(mod_overall) summary(mod_bygender) # On the log scale confint(mod_overall) confint(mod_bygender) # On the natural scale confint(mod_overall) %&gt;% exp() confint(mod_bygender) %&gt;% exp() Part 4: Interpretation and discussion Using both the confidence intervals and effect magnitudes, discuss the results of your analysis in a contextually meaningful way. (Tie these results back to the research questions.) Discuss limitations of your analysis by acknowledging the points in the analysis process that were most uncertain. Simulation study planning Describe in detail how you would implement a simulation study to study the impact of model misspecfication (incorrect form) on the accuracy of regression for estimating causal effects. It may help to draw a specific small causal graph as the basis of your simulation. "],["inverse-probability-weighting.html", "Topic 11 Inverse Probability Weighting Learning Goals Exercises Debrief", " Topic 11 Inverse Probability Weighting Learning Goals Connect inverse probability weighting to the exchangeability computations we have done previously Slides from today are available here. Exercises We‚Äôll do Exercises 1 and 2 as a class. You‚Äôll work on Exercise 3 and 4 in groups. Exercise 1 Assume that we have conditional exchangeability given \\(Z\\). For the outcome, let high = 1, low = 0. \\(n\\) \\(Z\\) \\(A\\) \\(Y\\) 30 1 1 90% high (27), 10% low (3) 30 1 0 40% high (12), 60% low (18) 30 0 1 70% high (21), 30% low (9) 10 0 0 20% high (2), 80% low (8) Create columns \\(Y^{a=1}\\) and \\(Y^{a=0}\\), and fill them in using the conditional exchangeability assumption. Within \\(Y^{a=1}\\) and \\(Y^{a=0}\\), total the number of highs and lows within \\(Z=1\\) and within \\(Z=0\\). Verify that you would get the same totals by‚Ä¶ Scaling the 30 with Z=1, A=1 up to 60 by giving the original 30 a weight of 2. Scaling the 30 with Z=0, A=1 up to 40 by giving the original 30 a weight of 4/3. Scaling the 30 with Z=1, A=0 up to 60 by giving the original 30 a weight of 2. Scaling the 10 with Z=0, A=0 up to 40 by giving the original 10 a weight of 4. How are all of these weights related to the fraction of those who receive their particular value of treatment among the \\(Z\\) subgroup (\\(P(A\\mid Z)\\))? Write out the calculation for the ACE (\\(P(Y^{a=1}=\\text{high}) - P(Y^{a=0}=\\text{high})\\)) in two ways: Directly using the total number of highs in the two columns As a weighted mean We can view the data in columns \\(Y^{a=1}\\) and \\(Y^{a=0}\\) as a pseudopopulation in which all 100 units exist twice: once as their treated version and once as their untreated version. Verify that within \\(Z=1\\) half of the ‚Äúpseudounits‚Äù recive treatment and the other half don‚Äôt. Do the same for \\(Z=0\\). What does this tell us about the relationship between \\(Z\\) and \\(A\\) in the weighted sample (the pseudopopulation)? Exercise 2 Assume that we have conditional exchangeability given \\(Z\\). \\(n\\) \\(Z\\) \\(A\\) \\(E[Y\\mid A, Z]\\) 80 A 1 40 20 A 0 20 20 B 1 30 80 B 0 20 Create columns \\(E[Y^{a=1} \\mid Z]\\) and \\(E[Y^{a=0} \\mid Z]\\), and fill them in using the conditional exchangeability assumption. Within \\(Y^{a=1}\\) and \\(Y^{a=0}\\), find the total (sum) outcome within \\(Z=1\\) and within \\(Z=0\\). Verify that you would get the same totals by‚Ä¶ Scaling the 80 with Z=A, A=1 up to 100 by giving the original 80 a weight of 100/80. Scaling the 20 with Z=B, A=1 up to 100 by giving the original 30 a weight of 5. Scaling the 20 with Z=A, A=0 up to 100 by giving the original 30 a weight of 5. Scaling the 80 with Z=B, A=0 up to 100 by giving the original 10 a weight of 100/80. How are all of these weights related to the fraction of those who receive their particular value of treatment among the \\(Z\\) subgroup (\\(P(A\\mid Z)\\))? Write out the calculation for the ACE (\\(E[Y^{a=1}] - E[Y^{a=0}]\\)) in two ways: Directly using the total in the two columns As a weighted mean Verify that within \\(Z=A\\) half of the ‚Äúpseudounits‚Äù recive treatment and the other half don‚Äôt. Do the same for \\(Z=B\\). What does this tell us about the relationship between \\(Z\\) and \\(A\\) in the weighted sample (the pseudopopulation)? Exercise 3 Assume that we have conditional exchangeability given \\(Z\\). \\(n\\) \\(Z\\) \\(A\\) \\(Y\\) 10 1 1 60% high (6), 40% low (4) 40 1 0 50% high (20), 50% low (20) 10 0 1 50% high (5), 50% low (5) 50 0 0 40% high (20), 60% low (30) Use the same process we went through in Exercises 1 and 2 to compute the ACE (\\(P(Y^{a=1}=\\text{high}) - P(Y^{a=0}=\\text{high})\\)) in two ways: Directly using the total number of highs in the two columns (the ‚Äúold‚Äù way) As a weighted mean (inverse probability weighting (IPW)) Exercise 4 Assume that we have conditional exchangeability given \\(Z\\). \\(n\\) \\(Z\\) \\(A\\) \\(E[Y\\mid A, Z]\\) 80 A 1 30 20 A 0 20 40 B 1 60 60 B 0 10 Use the same process we went through in Exercises 1 and 2 to compute the ACE (\\(E[Y^{a=1}] - E[Y^{a=0}]\\)) in two ways: Directly using the total number of highs in the two columns (the ‚Äúold‚Äù way) As a weighted mean (IPW) Debrief What commonalities do you notice across the 4 exercises? What questions remain about inverse probability weighting? "],["ipw-simulation.html", "Topic 12 IPW: Simulation Learning Goals Exercises", " Topic 12 IPW: Simulation Learning Goals Use simulation to understand the importance of correct model specification on the performance of IPW and to verify the ‚Äúarrow-removing‚Äù property of IPW Slides from today are available here. Exercises You can download a template RMarkdown file to start from here. Exercise 1: Simulate We‚Äôll simulate data from the causal graph below where \\(Z\\), \\(W\\), and \\(A\\) are binary, and \\(Y\\) is quantitative. Use the structural equations below for \\(A\\) and \\(Y\\), and store your simulated data as sim_data. \\(\\log(\\mathrm{odds}(A = 1)) = -1 + 0.4 Z + 0.4 W + 0.9 Z*W\\) \\(Y\\) follows a normal distribution with mean \\(10 + 5A + 6Z + 7W\\) and standard deviation 2. Based on the structural equation for \\(Y\\), what is the true ACE? Based on the causal graph, what variables are needed to achieve conditional exchangeability? set.seed(451) n &lt;- 10000 Z &lt;- rbinom(n, size = 1, prob = 0.5) W &lt;- rbinom(n, size = 1, prob = 0.5) log_odds_A &lt;- odds_A &lt;- p_A &lt;- A &lt;- noise_Y &lt;- rnorm(___) mean_Y &lt;- Y &lt;- mean_Y + noise_Y sim_data &lt;- data.frame(Z = factor(Z), W = factor(W), A = factor(A), Y) Exercise 2: Inverse probability weighting Here, we‚Äôll check the performance of inverse probability weighting for estimating the average causal effect. The accuracy of IPW depends on having the right model for treatment as a function of the variables needed to achieve conditional exchangeability. Based on our simulation, what is the correct logistic regression model that should be fit? Fit this model as ps_mod_complex. Also fit a wrong model called ps_mod_simple that uses the formula A ~ Z + W. (In this way, we can explore the impact of model misspecification.) The code below uses your models to compute (right and wrong) IP weights. predict(logistic_mod, newdata = data_to_make_predictions_for, type = \"response\") is used to predict probabilities from a logistic regression model. (Without type = \"response\", log-odds are computed.) Add comments to this code to document these different pieces, and check in with the instructor if you have questions. sim_data &lt;- sim_data %&gt;% mutate( ps_simple = predict(ps_mod_simple, newdata = sim_data, type = &quot;response&quot;), ipw_simple = case_when( A==1 ~ 1/ps_simple, A==0 ~ 1/(1-ps_simple) ) ) %&gt;% mutate( ps_complex = predict(ps_mod_complex, newdata = sim_data, type = &quot;response&quot;), ipw_complex = case_when( A==1 ~ 1/ps_complex, A==0 ~ 1/(1-ps_complex) ) ) Fit an ordinary regression model Y ~ A that ignores the IP weights. Is the estimated ACE what you expected? Incorporate the IP weights into your analysis by modifying your model from part c as below. (As discussed in 12.4 of WHATIF, this weighting fits a marginal structural model (MSM) that allows us to directly estimate the ACE.) Is the estimated ACE what you expected? lm(..., data = ..., weights = ipw_simple) lm(..., data = ..., weights = ipw_complex) Note: Using weights = ... in glm(..., family = \"binomial\") does not work exactly the way we want it to. (It works as we want for lm().) Going forward, we will use a specialized package (the survey package) for dealing with weights. Exercise 3: Balance checking What is the key differentiator between regression and inverse probability weighting? Let‚Äôs verify that unique property of IP weighting. Make plots to show the relationship between \\(Z\\) and \\(A\\) and between \\(W\\) and \\(A\\) in the original, unweighted data. Modify your plot to incorporate the IP weights by adding the following to aes(). What property of IP weighting does this show? aes(..., weight = ipw_complex) "],["applied-analysis-ipw.html", "Topic 13 Applied Analysis: IPW Learning Goals Analysis", " Topic 13 Applied Analysis: IPW Learning Goals Conduct and interpret results from an appropriate IPW analysis to estimate causal effects and effect modification of causal effects. Slides from today are available here. Analysis You can download a template RMarkdown file to start from here. Data context and research questions Research questions: Does a policy that delays the tenure process (for new parents) actually help tenure outcomes? Does it help men and women equally? The data and full codebook are available on Moodle (aer_primarysample.csv and ReadMe.pdf). An abbreviated codebook is below: Treatment and primary outcome: gncs: Is a gender-neutral clock-stopping policy in place at this person‚Äôs school? (treatment) tenure_policy_school: Did this person get tenure at the university with the clock-stopping policy? (primary outcome) Additional outcomes (mediators): top_pubsX: cumulative number of peer-reviewed publications in top-5 journals by year X (3, 5, 7, and 9) since PhD completion PUBSX: cumulative number of non-top-5 peer-reviewed publications by year X (3, 5 7, and 9) since PhD completion Additional covariates: female: Is the faculty member a female? pol_u: policy university identifier (values are randomized for privacy reasons) pol_job_start: identifier for year the job at the policy university started (values are randomized for privacy reasons) phd_rank: 1-5 categorical variable of PhD program tier based on placements into the top-50 departments in our sample phd_rank_miss: indicator for missing PhD information post_doc: indicator for doing a post-doc before the first tenure-track position ug_students: number of undergraduate students at the university, in thousands grad_students: number of graduate students at the university, in thousands faculty: number of faculty at the university (all disciplines), in hundreds full_av_salary: average salary of full professors at the university, in thousands assist_av_salary: average salary of assistant professors at the university, in thousands, revenue: annual revenue of the university, in 10,000,000s female_ratio: fraction of the faculty at the university who are female full_ratio: fraction of the faculty at the university who are full professors RANK: equal to 1 for top-10 departments and 2 for all other departments max_csstops: number of children born within five years of PhD completion Loading data and packages You‚Äôll need to install the survey package first. library(survey) # install.packages(&quot;survey&quot;) library(tidyverse) library(splines) # Make sure that the splines package is installed before running tenure &lt;- read_csv(&quot;aer_primarysample.csv&quot;) tenure &lt;- tenure %&gt;% mutate( faculty = ifelse(faculty_miss==1, NA, faculty), revenue = ifelse(revenue_miss==1, NA, revenue), female_ratio = ifelse(female_ratio_miss==1, NA, female_ratio), full_ratio = ifelse(full_ratio_miss==1, NA, full_ratio), phd_rank = ifelse(phd_rank_miss==1, NA, phd_rank), max_csstops = ifelse(max_csstops_miss==1, NA, max_csstops) ) Part 1: Review outcome regression results Previously we used outcome regression to estimate the overall effect of tenure clock stopping policies and the effects for males and females. Models from one of our analyses are displayed here. Review the results of this analysis by interpreting the relevant coefficients and confidence intervals on the odds ratio scale. # Overall ACE mod_overall &lt;- glm(tenure_policy_school ~ gncs + ns(female_ratio, 3) + ns(full_ratio, 3) + factor(max_csstops)*female, data = tenure, family = &quot;binomial&quot;) summary(mod_overall) confint(mod_overall) # Subgroup ACEs mod_subgroup &lt;- glm(tenure_policy_school ~ gncs*female + ns(female_ratio, 3) + ns(full_ratio, 3) + factor(max_csstops)*female, data = tenure, family = &quot;binomial&quot;) summary(mod_subgroup) confint(mod_subgroup) Part 2: Propensity score modeling We will assume that the revenue, female_ratio, full_ratio, and max_csstops are sufficient (proxies for) variables needed to achieve conditional exchangeability. (female was included in the outcome regresion models for assessing subgroup effects but wasn‚Äôt determined to be part of a noncausal path in our causal graph analysis.) Fit an appropriate propensity score model called ps_mod. Use visualizations to inform the construction of your model. (Just focus on appropriately handling nonlinearity.) Use your model to compute appropriate weights, and add these weights to the dataset. Use ‚Äúbefore and after‚Äù visualizations to compare balance of key variables before and after weighting. You‚Äôll need to use factor(gncs) to make your visualizations‚Äìthis forces R to view gncs as a categorical variable. Note: If any distributions look dissimilar after weighting, this is an indication that the propensity score model may be misspecified. We won‚Äôt address this in our analysis today for time reasons, but in practice, more flexible modeling techniques would be explored. Coding notes: The code below will be useful for exploring nonlinearity in covariate-treatment relationships. The blue smooth reflects observed data trends, and the red smooth shows the predictions from a logistic regression model with a specific model formula. Formula y ~ x: Covariate is included as a linear term Formula y ~ ns(x,3): Covariate is modeled with a flexible nonlinear function (a ‚Äúspline‚Äù with 3 degrees of freedom‚Äìdon‚Äôt worry about the details of this) The model predictions should generally align with observed data trends. If they don‚Äôt line up well using formula y ~ x, update the formula to y ~ ns(x, 3) to see if there is an improvement. ggplot(DATA, aes(x = COVARIATE, y = OUTCOME)) + geom_point() + geom_smooth(se = FALSE, color = &quot;blue&quot;, method = &quot;loess&quot;) + geom_smooth(formula = INSERT_MODEL_FORMULA, method = &quot;glm&quot;, method.args = list(family=&quot;binomial&quot;), se = FALSE, color = &quot;red&quot; ) The (incomplete) code below is useful for computing appropriate weights: DATA &lt;- DATA %&gt;% mutate( ps = predict(ps_mod, newdata = DATA, type = &quot;response&quot;), ipw = case_when( TREAT_VAR==1 ~ ???, TREAT_VAR==0 ~ ??? ) ) You can incorporate weights into most ggplot2 figures by adding weight to the aesthetics: aes(..., weight = ip_weight) Part 3: Modeling with IP weights We can use the IP weights constructed above in a weighted regression model to estimate causal effects. Note: The svydesign() and svyglm() functions from the survey package are used to ensure that the weights are treated appropriately. (An updated (‚Äúrobust‚Äù) standard error calculation method is used to appropriately account for the fact that the IP weights are estimated and have uncertainty.) Note that we are removing cases with missing values for the weights. (These cases had missing values in the covariates used in the propensity score model.) You‚Äôll think about whether this biases the analysis in Part 4. The code for estimating the overall ACE is complete. Adapt this code to estimate subgroup ACEs in males and females. Using both the confidence intervals and effect magnitudes, discuss the results of your analysis in a contextually meaningful way. (Tie these results back to the research questions.) How do confidence interval widths compare to those from outcome regression? # Remove cases with missing weights tenure_subs &lt;- tenure %&gt;% filter(!is.na(ipw)) # Set up information about weights design &lt;- svydesign(ids = ~0, weights = tenure_subs$ipw, data = tenure_subs) # Fit a marginal structural model to estimate overall ACE overall_fit &lt;- svyglm( tenure_policy_school ~ gncs, data = tenure_subs, design = design, family = &quot;quasibinomial&quot; ) summary(overall_fit) confint(overall_fit) # Adapt the svyglm() code above to include an interaction between treatment and female subgroup_fit &lt;- Part 4: Causal graphs and missing data Challenge! How might we use causal graphs to analyze the impact of dropping missing data (a complete case analysis)? Can we use ideas from representing selection bias with causal graphs? "],["time-varying-treatments-and-mediation-analysis.html", "Topic 14 Time-Varying Treatments and Mediation Analysis Learning Goals Exercises", " Topic 14 Time-Varying Treatments and Mediation Analysis Learning Goals Formulate research questions that can be answered in a time-varying treatment setting Formulate research questions that can be answered via mediation analysis Explain why regression does not generally work in time-varying settings with treatment-confounder feedback using d-separation ideas Relate d-separation ideas to exchangeability conditions for mediation Slides from today are available here. Exercises Exercise 1 For those of you working on a data analysis (or a plan of a data analysis) for the final project, share your data context and research questions with others. Mediation Brainstorm some research questions that could be answered in a mediation analysis framework. What mediators would be of interest? (That is, what direct and indirect effects would be of interest?) How realistic would it be to collect data on those mediators? Time-varying treatments Brainstorm some research questions that could be answered in a time-varying treatments framework. Is it more useful to consider time-fixed or time-varying treatments in your context? How realistic would it be to collect the longitudinal data needed for a time-varying treatments analysis? Exercise 2 The following causal graph shows a time-varying treatment setting where treatment is measured at two time points (A0 and A1). It depicts a common occurrence in longitudinal data: treatment-confounder feedback. This is when past treatment \\(A_{t-1}\\) affects the value of future confounders \\(L_{t}\\). Using causal graph ideas, explain why a regression model of the form \\(E[Y \\mid A_0, A_1, L_1]\\) creates a problem for estimating the effect of a treatment strategy for \\(A_0\\) and \\(A_1\\). How would you expect this graph to change under inverse probability weighting? Why does IPW allow us to estimate the effect of a treatment strategy for \\(A_0\\) and \\(A_1\\)? Exercise 3 In mediation analysis, a common first instinct to estimate direct effects is to control for the mediator by including it in a regression model. Let‚Äôs explore this intuition by examining the following causal graph. Based on this graph, what considerations need to be kept in mind in order for this approach to validly estimate a direct effect? "],["sensitivity-analyses-for-unmeasured-variables.html", "Topic 15 Sensitivity Analyses for Unmeasured Variables Learning Goals Example with the tipr package Discussion questions", " Topic 15 Sensitivity Analyses for Unmeasured Variables Learning Goals Evaluate the sensitivity of findings to data quality and propose appropriate sensitivity analyses for a research investigation. Conduct and communicate the results of a sensitivity analysis for unmeasured confounding. Slides from today are available here. Example with the tipr package Let‚Äôs go through a sensitivity analysis for the results of our tenure policy study. We estimated a causal odds ratio of 1.65 in our tenure policy analyses. An unmeasured confounder that we might concerned about is ‚Äúharshness of external reviewers.‚Äù We might conceive of quantifying this as the reviewers‚Äô expectation of number of publications in the pre-tenure time period. The adjust_or_with_continuous() function calculates updated (adjusted) causal odds ratios after considering a continuous unmeasured confounder (normal distribution with mean \\(m_1\\) in the treated group, mean \\(m_0\\) in the control group, and standard deviation of 1). The arguments are as follows: effect_observed: The actual OR that we estimated exposure_confounder_effect: Difference in means of the unobserved confounder in the treatment and control groups (\\(m_1 - m_0\\)) confounder_outcome_effect: Relationship between the unmeasured confounder and the outcome (quantified with an odds ratio) verbose: Whether or not to display status messages or_correction: Set to TRUE if the outcome prevalence is greater than 15% library(tipr) library(tidyverse) ## ‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ ## ‚úî dplyr 1.1.0 ‚úî readr 2.1.4 ## ‚úî forcats 1.0.0 ‚úî stringr 1.5.0 ## ‚úî ggplot2 3.4.1 ‚úî tibble 3.1.8 ## ‚úî lubridate 1.9.2 ‚úî tidyr 1.3.0 ## ‚úî purrr 1.0.1 ## ‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ ## ‚úñ dplyr::filter() masks stats::filter() ## ‚úñ dplyr::lag() masks stats::lag() ## ‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors # Below we set up a grid of 25 combinations of exposure_confounder_effect and confounder_outcome_effect using rep() sens_results &lt;- adjust_or_with_continuous( effect_observed = 1.65, exposure_confounder_effect = rep(-seq(0.5, by = 0.5, length.out = 5), times = 5), confounder_outcome_effect = rep(seq(0.2, 0.9, length.out = 5), each = 5), verbose = FALSE, or_correction = TRUE ) # The parameter combinations in the above analysis data.frame( exposure_confounder_effect = rep(-seq(0.5, by = 0.5, length.out = 5), times = 5), confounder_outcome_effect = rep(seq(0.2, 0.9, length.out = 5), each = 5) ) ## exposure_confounder_effect confounder_outcome_effect ## 1 -0.5 0.200 ## 2 -1.0 0.200 ## 3 -1.5 0.200 ## 4 -2.0 0.200 ## 5 -2.5 0.200 ## 6 -0.5 0.375 ## 7 -1.0 0.375 ## 8 -1.5 0.375 ## 9 -2.0 0.375 ## 10 -2.5 0.375 ## 11 -0.5 0.550 ## 12 -1.0 0.550 ## 13 -1.5 0.550 ## 14 -2.0 0.550 ## 15 -2.5 0.550 ## 16 -0.5 0.725 ## 17 -1.0 0.725 ## 18 -1.5 0.725 ## 19 -2.0 0.725 ## 20 -2.5 0.725 ## 21 -0.5 0.900 ## 22 -1.0 0.900 ## 23 -1.5 0.900 ## 24 -2.0 0.900 ## 25 -2.5 0.900 ggplot(sens_results,aes(x = confounder_outcome_effect, y = rr_adjusted, color = factor(exposure_confounder_effect))) + geom_hline(yintercept = sens_results$rr_observed[1], lty = 2) + geom_hline(yintercept = 1, lwd = 2, color = &quot;red&quot;) + geom_point() + geom_line() + labs(x = &quot;Unmeasured confounder - outcome effect (OR)&quot;, y = &quot;Adjusted OR&quot;) + guides(color = guide_legend(title = &quot;Treatment-confounder relationship\\n(mean difference)&quot;)) Discussion questions The above analysis looked at an unmeasured confounder that has a clear negative relationship with tenure outcomes. This informed the choice of the exposure_confounder_effect to be negative too. What would you expect to happen to our sensitivity analysis results plot if the exposure_confounder_effect had been positive? (That is, if faculty at schools with clock-stopping policies had higher publication expectations from reviewers than at schools without clock-stopping policies.) For those of you working on a data analysis (or a plan of a data analysis) for the final project, share your data context and research questions with others. What potential unmeasured confounders might you be concerned about in your analysis? How might you try to find reasonable values for the exposure_confounder_effect and confounder_outcome_effect parameters? "],["homework-1.html", "Homework 1 General instructions Part 1 Part 2 Part 3 Part 4 Part 5", " Homework 1 General instructions Due: Friday, January 27 at midnight CST. Set up a single Google Doc that you will use for your homework responses (and revisions) all semester. (A single doc facilitates seeing feedback and revisions over time.) Share this Google Doc with the instructor and preceptor with either edit or comment access by the due date. Part 1 Related to course components: Metacognitive Reflection, Enduring Concept Our first day discussions prompted different ways of thinking about causation. How did these discussions affect how you might think about causation going forward? In your response: Incorporate thoughts from all 4 prompts (Considering causes, Sinful saying or mandatory mantra?, Sufficiency and necessity, Evaluating evidence for causation: Bradford Hill criteria) Incorporate self-noticings and peer-noticings Suggestion: Write as if you were going to publish a blog post entitled ‚Äú10 things you probably never realized about causation‚Äù (or some number other than 10) No length requirement/restriction, but suggested to stay under 500 words Part 2 Related to course components: Enduring Concept When, if ever, is a direct comparison of the observed outcomes in the treated and untreated a good estimate of an average causal effect? Explain your answer with relevant discussion of exchangeability and study designs. Part 3 Related to course components: Important Concept The table below shows data on a binary outcome \\(A\\), a binary covariate \\(Z\\), and a quantitative outcome \\(Y\\). Assume that the treatment groups are conditionally exchangeable given \\(Z\\). \\(Z\\) \\(A\\) \\(Y\\) A 1 40 A 1 40 A 1 40 A 1 40 B 1 20 B 1 20 A 0 30 A 0 30 B 0 10 B 0 10 B 0 10 B 0 10 Estimate the average causal effect \\(E[Y^{a=1}-Y^{a=0}]\\). Show and explain your work. Does marginal exchangeability hold? Show and explain your work. Part 4 Related to course components: Enduring Concept Let‚Äôs think about study designs in terms of something you would genuinely want to study! What are you obsessed with? What do you find yourself thinking about all the time? What do you wish came up in conversation more often? (What‚Äôs your ‚Äúlightning lure‚Äù?) What is a causal question that you wish you could answer related to that obsession? What study design would be most feasible to implement to answer that question? In your response, please also discuss why you think other designs would not be as feasible. Part 5 Related to course components: Metacognitive Reflection How do you feel about your level of understanding for the Exchangeability and Study Designs topics? What were some notable themes in self- and peer-noticings? How do these reflections inform your next steps for developing stronger understanding and/or advising future students learning about these topics? "],["homework-2.html", "Homework 2 General instructions Revisions Part 1 Part 2", " Homework 2 General instructions Due: Friday, February 3 at midnight CST. Continue using the same Google Doc from HW1. Revisions If you would like to make revisions to any parts of Homework 1, please do the following: Keep all old writing and feedback intact Write an updated response just below your previous response and highlight the new writing in yellow Part 1 Chains, forks, and colliders are the building blocks for causal graphs and the stepping stones for understanding how bias arises when estimating causal effects. What ideas from Topics 4 and 5 (Causal Graphs as Statistical Models and Key Structures in Causal Graphs) would you categorize as an Enduring Concept, Important Concept, or a Concept Worth Being Familiar With? Why? (Refer to our syllabus for descriptions of these concept types.) Write your own explanation for the intuition behind the marginal and conditional (in)dependence relations in chains, forks, and colliders. Try to use examples that are different from the ones in the pre-class concept videos. Your writing should be accessible to an audience who has not taken Probability. Part 2 Related to course components: Metacognitive Reflection Has your level of understanding for the Exchangeability and Study Designs topics changed since Homework 1? If so, how and why? How do you feel about your level of understanding Topics 4 and 5 (Causal Graphs as Statistical Models and Key Structures in Causal Graphs)? What were some notable themes in self- and peer-noticings? How do these reflections inform your next steps for developing stronger understanding and/or advising future students learning about these topics? "],["homework-3.html", "Homework 3 General instructions Revisions Clarifying the big picture The smoking-birthweight paradox Exchangeability: Computation Exchangeability: explaining via causal graphs Simulation, d-separation, and exchangeability Study designs: examples of applied studies Metacognitive Reflection", " Homework 3 General instructions Due: Friday, February 17 at midnight CST. (Note that we‚Äôre skipping a week in our prior weekly HW cadence.) Continue using the same Google Doc from HW1. You do not need to complete all parts (except the Metacognitive Reflection). Just complete the parts that align with your learning goals and would be most helpful in developing strong understanding. If you‚Äôre interested in working on something not listed here, I‚Äôm very open to that too. Talk with me about what you‚Äôre thinking, and we‚Äôll come up with a good collection of work to further your goals. Revisions If you would like to make revisions to any parts of prior assignments, please do the following: Keep all old writing and feedback intact Un-highlight yellow text that has already been addressed with feedback and revisions Write an updated response just below your previous response and highlight the new writing in yellow Clarifying the big picture Tell a story/give a summary of our course up to this point by writing a piece that connects the following ideas: Potential outcomes and causal effects Exchangeability Causal graphs Causal and noncausal paths D-separation Building causal graphs in practice for applied analyses Audience: If you have a personal website or would like to create one, what you write here has the potential to make for a great blog post. If this appeals to you, think of who you would want to read such a piece (e.g., a potential employer, a friend, a family member), and write for them. Note: As we continue to move forward with new ideas in the course, you may find it helpful to continue incorporating the new ideas into what you write here. The smoking-birthweight paradox Write a piece summarizing the arguments and key takeaway messages from our discussion of the The Birth Weight ‚ÄúParadox‚Äù Uncovered?. If you‚Äôre curious about even further commentary on that article, read Commentary: Resolutions of the birthweight paradox: competing explanations and analytical insights, and incorporate your synthesis of the arguments in this paper. Audience: If you have a personal website or would like to create one, what you write here has the potential to make for a great blog post. If this appeals to you, think of who you would want to read such a piece (e.g., a potential employer, a friend, a family member), and write for them. Exchangeability: Computation Suppose that the treatment (\\(A\\)) groups are exchangeable conditional on \\(Z\\). Given the table of information below, compute the following average causal effects (showing your work): Overall ACE: \\(E[Y^{a=1} - Y^{a=0}]\\) ACE within \\(Z = A\\): \\(E[Y^{a=1} - Y^{a=0} \\mid Z = A]\\) ACE within \\(Z = B\\): \\(E[Y^{a=1} - Y^{a=0} \\mid Z = B]\\) (\\(Z\\) and \\(A\\) are binary, and \\(Y\\) is quantitative. \\(n\\) indicates the sample size for the 4 groups.) \\(n\\) \\(Z\\) \\(A\\) \\(E[Y\\mid A, Z]\\) 80 A 1 40 20 A 0 20 20 B 1 30 80 B 0 20 Exchangeability: explaining via causal graphs Causal graphs and the ideas of causal/noncausal paths can help clarify the concept of exchangeability. Use a causal graph to generate a numeric example of a potential outcomes table (containing information on covariate(s), treatment, and both potential outcomes) in which marginal exchangeability does not hold but conditional exchangeability does. If you would like to keep going, also use a causal graph to create a numeric example where marginal exchangeability does hold but conditional exchangeability does not. Simulation, d-separation, and exchangeability Pick any causal graphs from our in-class exercises or textbooks (WHATIF and/or PRIMER) that surprised or perplexed you. For a given graph: Use d-separation to identify appropriate conditioning set(s) of variables that would allow for valid estimation of the average causal effect. Check that those conditioning set(s) actually result in conditional exchangeability by performing a simulation study. (It is important to perform many runs of the simulation. Check the Topic 5 Solutions on Moodle for guidance.) Study designs: examples of applied studies If you would like to see more examples of how study designs are used in applied research, find some applied papers and read enough of each to get a sense for how the study was conducted. Summarize your findings here. Metacognitive Reflection How do you feel about your level of understanding of prior topics and new topics (causal/noncausal paths, d-separation, building causal graphs in practice)? What were some notable themes in self- and peer-noticings? How do these reflections inform your next steps for developing stronger understanding? What support and resources would best help you? "],["homework-4.html", "Homework 4 General instructions Revisions Drawing causal graphs General workflow for regression and IPW Metacognitive Reflection Final Project Proposal", " Homework 4 General instructions Note: Two different due dates for main exercises and for project proposal Main exercises (Revisions, Drawing causal graphs, General workflow for regression and IPW, and Metacognitive Reflection) due Friday, March 3 at midnight CST. Final project proposal due Friday, March 10 at midnight CST. Continue using the same Google Doc from HW1 for both the main exercises and project proposal. Revisions If you would like to make revisions to any parts of prior assignments, please do the following: Keep all old writing and feedback intact Un-highlight yellow text that has already been addressed with feedback and revisions Write an updated response just below your previous response and highlight the new writing in yellow Drawing causal graphs Read the Drawing Causal Diagrams chapter of The Effect, an online causal inference textbook by Nick Huntington-Klein. What ideas from our causal graph construction activity (Topic 9) were reinforced from this reading? What new ideas were presented that you found helpful? What ideas were you unsure about or disagreed with? General workflow for regression and IPW Write a general workflow for conducting (1) an outcome regression analysis and (2) an inverse probability weighting analysis to estimate average causal effects (overall effects and subgroup effects). Provide guidance for the causal graph construction stage Describe any steps that should be taken before modeling and their purpose Describe the models that should be fit and the output that is used Describe the balance checks (diagnostics) that should accompany an IPW analysis and their rationale Describe general limitations to be wary of in these analyses (What parts of the analysis process that are generally most uncertain?) Metacognitive Reflection We will be having 1-on-1 learning conferences the week before Spring Break (3/6 - 3/10) to discuss your learning so far and your course goals. The goal of this reflection is to prepare for these conferences. Please directly address all of the following prompts: What are your goals for this course? What are you hoping to be able to do or understand deeply by the end of the semester? How do you feel about your progress towards these learning goals? What can you do, and what can the instructor do to make the remainder of the semester as successful as possible? For each of the following topics, comment on what you understand well and what you don‚Äôt understand as well. In doing so, please look back at your homework responses and feedback. Does my Enduring/Important/Familiar breakdown below align with your opinions of what ideas are important? (If they differ, that‚Äôs fine - let‚Äôs discuss.) Enduring concepts: Potential outcomes and their role in defining causal effects The fundamental problem of causal inference (We can only ever observe a single potential outcome for any unit.) The big picture idea behind the assumption of exchangeability (not necessarily at the level of conditional independence) Why are randomized experiments the ‚Äúgold standard‚Äù for causal inference? What role do causal graphs play in a causal analysis? Important concepts: Applying the concept of exchangeability to estimate causal effects from small datasets by hand The rationale behind quasi-experimental designs Causal and noncausal paths, d-separation, exchangeability and the links between these ideas Workflow for conducting outcome regression and IPW analyses How are simulation studies useful for understanding statistical ideas and exploring properties of statistical methods? Concepts worth being familiar with: Causal Markov assumption / product decomposition rule Implementation of simulations to understand statistical ideas and study properties of statistical methods What new types of research questions can we pose with the time-varying treatments framework? Based on your responses above, propose a midterm grade for yourself using the guidelines discussed on page 4 of our syllabus. I will read your reflection before our conference. The goal of our conference will be to discuss your progress so far and to clarify a plan for the remainder of the semester. We‚Äôll also discuss your plans for the final project to ensure that it has good scope and aligns with your goals. Final Project Proposal Take a look at our Final Project page and complete the Project Proposal described under the Timeline section, Deadline 1. Put your responses in a new ‚ÄúFinal Project Proposal‚Äù section of your Google Doc for this course. "],["homework-5.html", "Homework 5 General instructions Revisions Project Work (REQD) Metacognitive Reflection (REQD) Sensitivity analysis for unmeasured confounding (REQD) Causal discovery (REQD)", " Homework 5 General instructions Due Friday, March 31 at midnight CST. Please complete the exercises marked (REQD). (Project Work, Metacognitive Reflection, Sensitivity Analysis, and Causal Discovery) The other exercises provide opportunities to explore ideas more deeply and re-engage with past ideas. Complete whatever aligns with your goals. Revisions If you would like to make revisions to any parts of prior assignments, please do the following: Keep all old writing and feedback intact Un-highlight yellow text that has already been addressed with feedback and revisions Write an updated response just below your previous response and highlight the new writing in yellow Project Work (REQD) Take a look at our Final Project page and make as much progress as you can towards Milestone 2. Create a separate Google Doc for your project work, and share this document with the instructor. (Just create one Google Doc per team if you‚Äôre working with teammates.) This project-specific Google Doc is where intermediate work and feedback will be recorded even if the ultimate deliverable ends up being something other than a written report (e.g., presentation, website). Metacognitive Reflection (REQD) For this reflection, check in on your understanding of our new topics in light of the breakdown below (which you can disagree with!). (Do this reflection after the main exercises.) Enduring concepts: Why do we do sensitivity analyses for unmeasured variables and how, in general, do we interpret results? What is the goal of causal discovery? Important concepts: Making connections between the probability underlying casual graphs and why we need to specify parameters in sensitivity analyses Details of how the causal discovery algorithm covered in the concept video Concepts worth being familiar with: What do you think should go under this category? Sensitivity analysis for unmeasured confounding (REQD) Context Does smoking actually cause lung cancer? There was great debate in the 1950s and 1960s on this issue. A prominent statistician R. A. Fisher (a longtime smoker) was dubious of the actual causal relationship and proposed that some genetic variant might be more common in smokers and also increase lung cancer risk. In the paper Smoking and lung cancer: recent evidence and a discussion of some questions, Jerome Cornfield and co-authors report on a sensitivity analysis for unmeasured confounding to address Fisher‚Äôs proposition (second column on page 1186). We‚Äôll corroborate these results in this exercise. Implementation with tipr Use the adjust_rr_with_binary() function in the tipr package to implement a sensitivity analysis. rr stands for relative risk and is a probability ratio (as opposed to an odds ratio). Relative risks are alternate effect measures for binary outcomes. First look at the documentation for this function. Note that because our causal effect is a relative risk, the confounder_outcome_effect is also quantified with a relative risk. Use the seq() function to generate a sequence of regularly spaced values for the exposed_confounder_prev, unexposed_confounder_prev, and confounder_outcome_effect arguments. Look at the documentation for the seq() function to understand how the arguments work. The only background information that we‚Äôre starting with is A recent study suggests that the causal effect (before considering any unmeasured confounders) is a relative risk of about 7. library(tidyverse) library(tipr) # This creates all combinations of values across the 3 parameters parameter_combos &lt;- tidyr::crossing( exposed_confounder_prev = seq(from = ___, to = ___, by = ___), unexposed_confounder_prev = seq(from = ___, to = ___, by = ___), confounder_outcome_effect = seq(from = ___, to = ___, by = ___) ) # Use dplyr::filter() to remove combinations that won&#39;t &quot;explain away&quot; (make null) the observed causal effect # i.e., make sure that the parameters indicate the correct sign of the U-&gt;A relationship parameter_combos &lt;- parameter_combos %&gt;% filter() # Run sensitivity analysis sens_results &lt;- adjust_rr_with_binary( effect_observed = ___, exposed_confounder_prev = parameter_combos$exposed_confounder_prev, unexposed_confounder_prev = parameter_combos$unexposed_confounder_prev, confounder_outcome_effect = parameter_combos$confounder_outcome_effect, verbose = FALSE ) Visualize Visualize the sensitivity analysis results in a way that you find effective. The instructor found it helpful to collapse the exposed_confounder_prev and unexposed_confounder_prev parameters into a single parameter: You may find it helpful to show all 3 parameters directly in your visualization. Interpret Explain the general trends you see in your visualization. Use both your visualization and the sens_results data frame to identify what parameter combinations nullify the observed causal effect (at least approximately). Based on these results, comment on the robustness of the original causal effect estimate. Describe what background research you might need to conduct to contextualize how realistic the nullifying parameters are. Causal discovery (REQD) Exercise 1 Consider data that truly come from a fork X &lt;- Y -&gt; Z. What pattern would a causal discovery algorithm report? If you could supply prior knowledge to the algorithm on only one edge that is required to be present, what edge (if any) would allow the entire structure to be learned? Explain briefly. Exercise 2 We have learned the following structure from the skeleton building phase. We have the following results from conditional independence tests (\\(H_0\\) indicates conditional independence, significance level = 0.01): \\(X \\perp\\!\\!\\!\\perp Z \\mid Y\\)? p-value = 0.001 \\(X \\perp\\!\\!\\!\\perp W \\mid Y\\)? p-value = 0.1 \\(Y \\perp\\!\\!\\!\\perp V \\mid W\\)? p-value = 0.1 \\(U \\perp\\!\\!\\!\\perp W \\mid V\\)? p-value = 0.1 What pattern would a causal discovery algorithm report? Show your work. Exercise 3 We have measured 3 variables \\(X\\), \\(Y\\), and \\(Z\\) (all quantitative). You can read in the data below. disc_data &lt;- readr::read_csv(&quot;https://www.dropbox.com/s/moj3k3fed7puicr/discovery_data.csv?dl=1&quot;) Step through the causal discovery process, using regression models as your conditional independence test. Use a type 1 error rate (significance level) of \\(\\alpha=0.01\\). Show all work. This involves: Showing model output. Writing a sentence using numbers from the output at each step to show the decisions made by the algorithm. Report the final output that the discovery algorithm would give. Simulation study for sensitivity analyses Conduct a simulation where the true average causal effect is zero but where there is an unmeasured confounder with U-&gt;A and U-&gt;Y effect magnitudes that you set. Use the tipr package to investigate if sensitivity analysis results align with your simulation setup. (You‚Äôll have to look through the package documentation to find the right sensitivity analysis function.) Learning about mediation analysis Mediation analysis was a topic that we were going to talk about on Monday, March 20. We may come back to it after we finish the other topics on our schedule, but if you‚Äôd like to learn a little more about this topic, check out the following resources: YouTube video (with slides) Overview paper: Nguyen, T. Q., Schmid, I., &amp; Stuart, E. A. (2020). Clarifying causal mediation analysis for the applied researcher: Defining effects based on what we want to learn. Psychological Methods. https://doi.org/10.1037/met0000299 Randomized experiments This exercise can help work through the idea that randomized experiments are the ‚Äúgold standard‚Äù for causal inference. Simulate data from a fork structure where U is a common cause of A and Y. In the part of your code when you simulate Y, also simulate the potential outcomes under treatment and control (Ya1 and Ya0) by setting the A part equal to 1 for Ya1 and 0 for Ya0. Create a new version of treatment called A_rand which is a randomly assigned treatment (in contrast to naturally-occurring treatment A which is affected by Z) using the sample() function: # This randomly assigns half of the units to treatment and half to control A_rand &lt;- sample(rep(c(0,1), each = n/2)) # n is the simulation sample size Check whether marginal exchangeability holds for the natural version of treatment A. Repeat for the randomized version of treatment A_rand. Summarize what you learn from these investigations. "],["final-project.html", "Final Project Project Options Deliverables Timeline", " Final Project My sole hope for this project is for it to further your goals for taking this course. Let‚Äôs collaborate to make it a good experience for you. Project Options Option 1: Data analysis Collaboration: Groups of up to 3. Individual work is fine. Perform a causal analysis on a dataset of your choice. The methods you use for analysis will vary depending on your research questions and the structure of your data (e.g., different methods for quasi-experimental designs vs.¬†general observational studies). You‚Äôll plan your methods in collaboration with the instructor. A key part of all analyses will be sensitivity analyses to assess robustness of results to points of uncertainty in the analysis process. Resources for finding data: Google Dataset Search Harvard Dataverse Inter-university Consortium for Political and Social Research (ICPSR) IPUMS Macalester‚Äôs librarians can also be a great resource for finding data. Schedule an appointment with them here. Option 2: Blog posts Collaboration: Individual only. Write two blog posts explaining causal inference ideas to a general audience. Post 1: A Tour of Causal Inference Which of our course ideas resonated most with you? Lead the reader through these topics in an engaging and cohesive way. Post 2: Pick any media item that has interested you. Write a reaction to it / an analysis of it from a causal inference perspective. If you‚Äôre looking to explore some media, the Casual Inference podcast is a fun one! Option 3: Learn an advanced topic Collaboration: Groups of up to 3. Individual work is fine. Dig deeper into existing course topics or learn a new topic. Examples could include: Methods for transportability (generalizability) of effects Interference Details of methods for time-varying treatments Specialized considerations for particular study designs Doubly-robust estimation Option 4: Other If none of these options piques your interest, I‚Äôm happy to discuss alternatives with you. Some ideas: Design a Shiny app to illustrate causal concepts to students Write (part of) an R package for making it easier to work with causal graphs Deliverables There is a lot of flexibility in the form that your project takes. Examples include: A video presentation A podcast-style recording A set of blog posts A project webpage on a personal website Work with the instructor to determine the most suitable deliverable for your project, depending on the option you pick. Timeline Milestone 1: Project Proposal Choose your final project option, topic, and group by Friday, March 10 at midnight CST. Data analysis option: Find a dataset and formulate causal question(s) that you want to answer. Blog post option: Outline ideas for one post Advanced topic option: Settle on an advanced topic, and do some preliminary research to identify key ideas within this topic. Milestone 2: Friday, March 31 Data analysis option: Understand your data context well and construct an initial causal graph. Blog post option: Brainstorm ideas or create an outline for one post. Advanced topic option: Make progress in learning about one sub-area for your topic. Other: Make progress appropriate to the scope of the project. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
